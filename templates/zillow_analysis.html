{% extends '_base.html' %}
{% block title %}Zillow Analysis{% endblock %}
{% block content %}
    <head>
        <link rel="stylesheet" href="{{ url_for('static', filename='zillow_analysis_style.css')}}">
        <script src="https://cdn.plot.ly/plotly-latest.min.js" charset = 'UTF-8'></script>
        <link rel="stylesheet" href="https://cdn.plot.ly/plotly.css">
    </head>

    <body>

        <main>

            <h1>Housing Price Prediction</h1>


            <p>This analysis was motivated by the following question: Can the collected data from Yelp be used to
                approximate the average housing price of a zip code? </p>

            <p>Data was collected from Yelp using its API and a model was created to try and predict the average cost of
                a house by zip code. If the model shows promise perhaps it can be used to help predict future changes
                in housing price as the average price/rating/review_count of a zip codes’ restaurants increase or
                decrease. This could help with improving city logistics, ease gentrification, provide investing
                opportunities and much more. The idea being popular restaurants could be a proxy variable representing
                an increase in interest in a particular area and thus an increase in the average price of housing.</p>

            <h2>Data Constraints</h2>

            <p>The Yelp API like most if not all APIs limits the amount of times it can be “called” (data can be
                retrieved) in 24 hours. By data standards a relatively limited amount can be called per day, say 5000
                observations, which seems like a lot, however after cleaning the data (removing observations with: less
                than x reviews, missing important data, duplicates, irrelevant data, etc etc) the number of clean
                observations obtained a day comes down significantly. After collecting data over the combined time span
                of 6 weeks there are only about 80,000 total observations with about 2100 unique zip codes. Once the
                data was further clean and combined with the Zillow data there were exactly 2000 zip codes tested by the
                model. This is only  about 5% of the total zip codes in the US. Additionally not every restaurant on
                Yelp is in this data set including some of the most popular, highly reviewed/rated restaurants in every
                city.</p>

            <p>So the goal of the model is to try and help predict housing price. If it possible to do this the next
               step would be to try to use the data to forecast future housing prices based on changes in the
               restaurant scene of a city.</p>

            <h2>Variables</h2>

            <p>There are many variables to choose from and plenty more that would be useful but are inaccessible.
               Variables from both the Yelp data set and the Zillow data set were used. Below is a list of the
               variables and a brief description </p>

            <h3>Yelp</h3>

            <p><b>Number of Reviews</b> - How many reviews an individual business (restaurant in this case) has
                received. Presumably the reviews are monitored by Yelp and any obviously fake/bot reviews (overtly
                positive or negative) are removed and not considered by any part of the process on Yelp. The average,
                median and sum of Number of reviews for a zip code are used in the model.</p>

            <p><b>Rating</b> - On the yelp search page this a number of form X.Y in a range from 1 to 5 with 1.0 being
                worst and 5.0 being best. Data received from the API, limits the output to being whole numbers and their
                halves. For Example 4.2 is rounded down to 4 and 4.3 is rounded up to 4.5. This means there are only 9
                possibilities for rating, this is a massive loss of information. The average and median rating are used
                in the model.</p>

            <p><b>Price</b> - This is a pretty imprecise measurement. Yelp uses dollar signs ($) to measure the price
                and the only options are $, $$, $$$, $$$$ from cheapest to most expensive. What the measurement lacks in
                precision it makes up for in simplicity. The average and median rating are used in the model.
 </p>

            <h3>Zillow</h3>

            <p><b>Price</b> - The average price of a house in a given zip code</p>
            <p><b>City</b> - City in which the zip code is located </p>
            <p><b>State</b> - State in which the zip code is located</p>
            <p><b>Metro</b> - Greater Metro area in which the zip code is located</p>

            <h2>Creating the Model</h2>

            <p>There are many ways to analyze and learn about the relationship(s) between multiple variables Quickly
               becoming the most popular are machine learning algorithms. Some of these models are simple, others are
               complex; all of them aim to try and quantify the relationship between the chosen variables and hopefully
               better explain the world around us. </p>

            <p>Machine Learning can be broken down several ways. There are plenty of options to choose from when
                designing a model and new options are constantly being introduced into the community. The model chosen
                to examine this data set is a random forest. There are of course pros and cons for every approach.
                Before discussing these a quick description of a random forest. There is a simpler machine learning
                technique called ‘decision trees’. A random forest is a bunch of these trees analyzed together to come
                to a conclusion. So what is a decision tree? It is very similar to a game of twenty questions. The
                computer is asked a yes or no question and depending on the answer a path (branch) is formed until the
                computer arrives at an answer. This process is done over and over and over again until (hopefully) the
                computer is confident in where a given branch will lead. Below is an example of a decision tree.</p>

            <img class = 'decision-tree-pic' src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*E2br87UjCErSE2eqJ56DWQ.png" alt="Image Description">

            <p>In the above example if x(0)  is less than or equal to 5.5 the tree goes left and otherwise it goes right.
               If it goes left it arrives at its final answer. If it goes right it asks another yes or no question
               (less than or equal to 11.5) and then arrives at its answer. This branching out process is done as many
               times as it is needed (based on the amount of variables) in the model until each branch has reached an
               endpoint. </p>

            <p>The benefit of using a random forest are as followed:</p>

            <ul>
               <li>Good with non-linear relationships</li>
               <li>Good for higher dimensional space (Good with lots of variables) </li>
               <li>Not prone to overfitting</li>
               <li>Feature scaling general not needed</li>
               <li>Feature importance can be obtained</li>
            </ul>

            <p>Of course there are cons but for this model choice but for this purpose the pros outweigh the cons:</p>

               <ul>
                   <li>For large data sets it can be resource intensive (only 2000 observations for this data set)</li>
                   <li>It is a ‘black box model’ so it can be hard to understand the decision making process</li>
                   <li>Random Forests are known as ‘Greedy Algorithms’ meaning when faced with a decision it can never
                       see past the two options in front of it. Think about a mouse at a fork in the road in a maze.
                       It will always choose the path the most cheese in front of it even if the other path has more
                       total cheese because it cannot see the cheese down every different path in the maze.</li>
               </ul>

            <p>The variables in the model are listed above with Zillow Price being the dependent variable (what is being
               predicted). The data set  is relatively small so the model was trained on 75% of the data set (exactly
               1500 observations) and tested on the remaining 500 observations. As a reminder this data set is 2000
               rows of summary statistics (average and median mostly) there are in total about 80000 Yelp observations
               that are funneled into 2000 unique zip codes. </p>

            <h2>Evaluating the Model</h2>

            <p>There are two pretty common ways to quantitatively get a good look at how the model performed and they
               are Mean Squared Error and R<sup>2</sup> (coefficient of determination). Mean Squared Error is the average
               difference between the true value and the predicted value by the model, this number is then squared to
               both make it positive and to more heavily punish the more extreme misses.These squares are then summed
               and an average is found producing the final MSE. R<sup>2</sup> gives a numerical value between 0 and 1 which
               determines how much of the variance in the dependent variable is explained by the independent variables.
            </p>

            <p class = 'centered-text'><b>Mean Squared Error (MSE)</b>: 80,007,257,500.25774</p>
            <p class = 'centered-text'><b>R<sup>2</sup></b>: 0.5229242919073203</p>

            <p>Starting with MSE, at first glance this looks pretty awful. Remember this number is squared and the
               square root is $282,855.54. Which is still bad but there are few factors that could have led to this
               to be discussed later. </p>

            <p>The R<sup>2</sup> is actually quite good. For a real world scenario having a bit more than half the
               variance in the housing price be explained by the mostly Yelp data provided is encouraging for the
               prospect of the model moving forward. </p>

            <p>As mentioned, random forests are a black box model, meaning it is difficult to understand exactly what
               the model is ‘thinking’ or what is happening in its decision making process. Luckily there are few tools
               that give some insights on how it arrived at its conclusions</p>

            <p>Two kinds of residual analysis were done to take a look at where the model went wrong and where it was
               most often correct. The first shows the True vs the Predicted values and the second shows the differences
               by index.</p>

            <p>Looking at the below graph, the model is relatively accurate when the average house price is less than
               $750,000. There starts to be a breakdown from $750,000 to $1.00MM and anything after that is a disaster.
               Notice that the model never predicts anything over $1.76MM and there is only one other prediction greater
               than $1.5MM. It really struggles with the high dollar amounts, while being relatively accurate with the
               lower dollar houses </p>

            <img src="{{ url_for('static', filename='images/Housing_Price/True_vs_Prediction_YelpZillow_HousingPrice.png') }}">

            <p>Since the model loses accuracy as the price of the house increases this is going to significantly hinder
               its ability to help predict increasing housing prices based on Yelp activity (recall that is the end
               goal). This is reinforced by the seemingly hard cap at around $1.75MM. Going a step further if lines are
               placed at y  and x = 750K the graph looks like the following </p>

           <img src="{{ url_for('static', filename='images/Housing_Price/True_vs_Prediction_YelpZillow_HousingPrice_GreenLines.png') }}">

            <p>The below table details How many points are in each of the quadrants in the above graph.</p>


               <table border=1>
                   <tr>
                       <th>Quadrant</th>
                       <th>Number of Points</th>
                       <th>Percentage</th>
                   </tr>
                   <tr>
                       <td>Bottom Left</td>
                       <td>380</td>
                       <td>76%</td>
                   </tr>
                   <tr>
                       <td>Bottom Right</td>
                       <td>23</td>
                       <td>4.6%</td>
                   </tr>
                   <tr>
                       <td>Top Left</td>
                       <td>36</td>
                       <td>7.2%</td>
                   </tr>
                   <tr>
                       <td>Top Right</td>
                       <td>61</td>
                       <td>12.2%</td>
                   </tr>
               </table>

            <p>This is another encouraging sign. If the model can be better trained for more expensive houses then
               potentially it can have applications. </p>

            <p>This second residual analysis shows the differences (residuals) by index number and it looks pretty good.
               A decent portion of the difference are within the absolute value of 200K and nearly all of them are
               within 400K. It is of course by no means ideal but it is a place to start. The remaining 25 outliers are
               what are really punishing the MSE (as they should).</p>

            <img src="{{ url_for('static', filename='images/Housing_Price/ResidualAnalysisRFR_YelpZillow_HousingPrice.png') }}">

            <p>This in conjunction with the True vs Predict value graph shows that the model is almost being double
               punished by the outliers and might be suffering from overfitting. The outliers have these massive squared
               errors which contribute to the high MSE. Additionally it seems the model has a cap at 1.75M and is more
               reluctant to guess increasingly high numbers. So the issue that needs to be solved is accuracy for more
               expensive houses.</p>

            <p>The final piece of visualization is looking at which variables the model most highly prioritized when
               using the data to predict housing price. In the below graph no one variable has a dominant percentage.
            </p>

            <img src="{{ url_for('static', filename='images/Housing_Price/Feature_Importantce_RFR_YelpZillow_HousingPrice.png') }}">

            <p>The mean number of reviews was the most important feature but it capped out just above 25%. With two
               additional variables (review count median and mean price coming in at just below 15% and state coming in
               just behind the two of them at about 13%. These four variables are doing most of the work. </p>

            <p>A bit surprising, challenging the initial thought process behind the idea that spurred this analysis, is
               that restaurant rating looks to be essentially useless in the model evaluation of relative importance.
               This could be to the serious loss of information from the rounding when the data was received via the
               Yelp API. Even though these are averages and medians on a 1-5 scale. The small difference can make a big
               difference. In the downloaded data 4.3 is viewed the same as 4.7 and there is massive difference between
               4.7 and 4.8 (4.5 vs 5.0). Or of course it might be to random to help with the prediction.  </p>

            <p>Here are three graphs to show the biggest misses, closes predictions and the final one shows all of the
               data plotted on a map of the United States. The top map is all of the residuals plotted at the average
               coordinates of its zip code. The size and color of scales with the size of the difference. The color
               scale is pictured on the right and the as the circles get bigger so do the size of the miss. Size
               scale is based on the absolute value so negative values are not the smallest.</p>

            <div id="residuals-plot"></div>
            <script>
                var residualsFigure = {{ residuals_json|safe }};
                Plotly.newPlot('residuals-plot', residualsFigure.data, residualsFigure.layout);
            </script>

            <p>The second map shows the least accurate predictions from the model. These are the biggest circles from
               the map just above. The size scaling is less important on these since they are the worst predictions.
               This is just an easy way to visualize the worst of the worst.</p>

            <div id="least-accurate-plot"></div>
            <script>
                var leastAccurateFigure = {{ least_accurate_json|safe }};
                Plotly.newPlot('least-accurate-plot', leastAccurateFigure.data, leastAccurateFigure.layout);
            </script>

            <p>The final map shows the most accurate predictions from the model. These are the smallest circles from the
               first map. Again as with the least accurate map, the size and scaling is all relative and not as
               important. This is just an easy way to visualize the best of the best.</p>

            <div id="most-accurate-plot"></div>
            <script>
                var mostAccurateFigure = {{ most_accurate_json|safe }};
                Plotly.newPlot('most-accurate-plot', mostAccurateFigure.data, mostAccurateFigure.layout);
            </script>

           <h2>Conclusions</h2>

           <p>There is some promise to this model. It definitely is not perfect between the combination of skewed data
               and the overall lack of data. It is unclear how much of the total yelp data is included in the data set
               but it is surely <10% and probably significantly less than that. Only 2000 of the 41000 US zip codes
               are included. So there is room for significant improvement in this department. Unfortunately it is easy
               to identify this problem and not so easy to rectify.</p>

           <p> A  52% R<sup>2</sup> is not bad on its own and with all of the learnings from this process is encouraging
               for the next steps that can be taken with a more complete version of the data set. Of course it can be
               improved and the change in these variables can be monitored month to month to help predict a change in
               housing price but this data has plenty of use cases many of which have not been conceived.</p>

           <p>The biggest roadblock to the model is its performance for the more expensive housing prices. Obviously
               more data would help but based on its sporadic performance when price was greater than 750K there needs
               to be more adjustments to help this part of the model. Perhaps the data would respond better to a
               different type of analysis or maybe just the housing prices >750K (or some other value) should be
               evaluated by a different model (sort of like a piecewise function). The analysis has shown that this is
               an idea worth pursuing even if the initial thought behind using the Yelp data seems to be irrelevant.
           </p>

        </main>

    </body>
{% endblock %}